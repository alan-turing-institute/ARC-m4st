{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats.stats import kendalltau\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio vs. text source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = \"../outputs/wmt24/final\"\n",
    "hum_score_dir = \"../../mt-metrics-eval-data/mt-metrics-eval-v2/wmt24/human-scores\"\n",
    "docs_dir = \"../../mt-metrics-eval-data/mt-metrics-eval-v2/wmt24/documents\"\n",
    "sources_dir = \"../../mt-metrics-eval-data/mt-metrics-eval-v2/wmt24/sources\"\n",
    "wmt24_dir = \"../../mt-metrics-eval-data/mt-metrics-eval-v2/wmt24/metric-scores\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_dirs = os.scandir(wmt24_dir)\n",
    "\n",
    "for lp in lang_dirs:\n",
    "    if os.path.isdir(lp):\n",
    "        res_files = os.scandir(lp)\n",
    "        mm_mt = [f for f in res_files if \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_files = os.scandir(results_dir)\n",
    "results = []\n",
    "lang_pairs = []\n",
    "for res_file in res_files:\n",
    "    print(res_file.name)\n",
    "    if os.path.isfile(res_file):\n",
    "        res_df = pd.read_csv(res_file)\n",
    "        lang_pair = res_file.name.split('_')[0]\n",
    "        lp = lang_pair.split('-')\n",
    "        from_lang = lp[0]\n",
    "        to_lang = lp[1]\n",
    "        src_list_doc = f\"{docs_dir}/{from_lang}-{to_lang}.docs\"\n",
    "        src_doc = f\"{sources_dir}/{from_lang}-{to_lang}.txt\"\n",
    "        print(src_list_doc)\n",
    "\n",
    "        with open(src_list_doc) as input_file:\n",
    "            srcs_list = input_file.readlines()\n",
    "            speech_sources = [(i, s) for i, s in enumerate(srcs_list) if \"speech\" in s]\n",
    "\n",
    "        num_sentences = len(speech_sources)\n",
    "        wavfiles = [s for (i, s) in speech_sources]\n",
    "\n",
    "        with open(src_doc) as input_file:\n",
    "            src_sents = input_file.readlines()\n",
    "            speech_src_sents = [src_sents[s[0]] for s in speech_sources]\n",
    "\n",
    "        speech_src_sents = speech_src_sents * int(len(res_df) / num_sentences)\n",
    "        wavfiles = wavfiles * int(len(res_df) / num_sentences)\n",
    "        res_df['source_sent'] = speech_src_sents\n",
    "        res_df['wav'] = wavfiles\n",
    "        res_df['lang_pair'] = lang_pair\n",
    "        res_df['mt_system'] = res_df.mt_system.apply(lambda x: x.replace(\".txt\", \"\"))\n",
    "        results.append(res_df)\n",
    "        lang_pairs.append(lang_pair)\n",
    "\n",
    "print(len(results))\n",
    "print(len(lang_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(5, 2, figsize=(10, 20))\n",
    "axs = axs.flat\n",
    "\n",
    "tau_txt = []\n",
    "tau_audio = []\n",
    "all_hum_res = []\n",
    "\n",
    "for ix, lp in enumerate(lang_pairs):\n",
    "    lp_tuple = lp.split('-')\n",
    "    from_lang = lp_tuple[0]\n",
    "    to_lang = lp_tuple[1]\n",
    "    hum_score_file = glob.glob(f\"{hum_score_dir}/{lp}.*.seg.score\")[0]\n",
    "    src_list_doc = f\"{docs_dir}/{lp}.docs\"\n",
    "\n",
    "    with open(src_list_doc) as input_file:\n",
    "        srcs_list = input_file.readlines()\n",
    "\n",
    "    speech_sources = [i for i, s in enumerate(srcs_list) if \"speech\" in s]\n",
    "    hum_score = pd.read_csv(hum_score_file, delimiter=\"\\t\",\n",
    "                            names=[\"mt_system\", \"score\"])\n",
    "    mt_systems_mqm = np.unique(hum_score.mt_system)\n",
    "\n",
    "    hum_speech_only = []\n",
    "    for system in mt_systems_mqm:\n",
    "        sys_df = hum_score[hum_score.mt_system == system]\n",
    "        sys_df = sys_df.iloc[speech_sources]\n",
    "        hum_speech_only.append(sys_df)\n",
    "\n",
    "    hum_res = pd.concat(hum_speech_only)\n",
    "    all_hum_res.append(hum_res)\n",
    "    blaser_res = results[ix]\n",
    "\n",
    "    ranked_hum = hum_res.groupby('mt_system').mean().abs()\n",
    "    acs_order = \"mqm\" in hum_score_file\n",
    "    ranked_hum = ranked_hum.reset_index().sort_values('score', ascending=acs_order)\n",
    "    ranked_hum = ranked_hum.dropna()\n",
    "    ranked_hum['rank'] = range(1, len(ranked_hum)+1)\n",
    "\n",
    "    blaser_res = blaser_res[blaser_res.mt_system.isin(ranked_hum.mt_system)]\n",
    "    ranked_blaser_audio = blaser_res[['mt_system','audio_source']].groupby('mt_system')\n",
    "    ranked_blaser_audio = ranked_blaser_audio.mean().reset_index().sort_values(\n",
    "            'audio_source', ascending=False)\n",
    "    ranked_blaser_audio['rank'] = range(1, len(ranked_blaser_audio)+1)\n",
    "\n",
    "    ranked_blaser_text = blaser_res[['mt_system', 'text_source']].groupby('mt_system')\n",
    "    ranked_blaser_text = ranked_blaser_text.mean().reset_index().sort_values(\n",
    "            'text_source', ascending=False)\n",
    "    ranked_blaser_text['rank'] = range(1, len(ranked_blaser_text)+1)\n",
    "\n",
    "    merged_audio = pd.merge(ranked_hum, ranked_blaser_audio, on='mt_system')\n",
    "    merged_all = pd.merge(merged_audio, ranked_blaser_text, on='mt_system')\n",
    "\n",
    "    merged_renamed = merged_all[['mt_system',\n",
    "                             'rank_x',\n",
    "                             'rank_y',\n",
    "                             'rank']].rename(\n",
    "                                 columns={'rank_x': 'human',\n",
    "                                          'rank_y': 'text_src',\n",
    "                                          'rank': 'audio_src'})\n",
    "\n",
    "    corr_text = kendalltau(merged_renamed.human, merged_renamed.text_src)\n",
    "    corr_audio = kendalltau(merged_renamed.human, merged_renamed.audio_src)\n",
    "    tau_txt.append(corr_text.statistic)\n",
    "    tau_audio.append(corr_audio.statistic)\n",
    "\n",
    "    print(lp)\n",
    "    print(merged_renamed)\n",
    "    print(f\"Audio Tau = {corr_audio.statistic}\")\n",
    "    print(f\"Text Tau = {corr_text.statistic}\")\n",
    "\n",
    "    merged_renamed['rank_diff_txt'] = merged_renamed.human - merged_renamed.text_src\n",
    "    merged_renamed['rank_diff_au'] = merged_renamed.human - merged_renamed.audio_src\n",
    "    merged_renamed = merged_renamed.sort_values(by='human')\n",
    "\n",
    "    g_txt = sns.scatterplot(merged_renamed, x='mt_system',\n",
    "                        y='rank_diff_txt',\n",
    "                        ax=axs[ix],\n",
    "                        s=70,\n",
    "                        label='Text source')\n",
    "    g_au = sns.scatterplot(merged_renamed, x='mt_system',\n",
    "                        y='rank_diff_au',\n",
    "                        ax=axs[ix],\n",
    "                        s=70,\n",
    "                        label='Audio source')\n",
    "    axs[ix].set_title(lp)\n",
    "    axs[ix].axhline(y=0, linewidth=2, color='red', ls='--', lw=1)\n",
    "    g_txt.set_xlabel(\"Mt system\")\n",
    "    g_txt.set_ylabel(\"Rank difference (Human - BLASER)\")\n",
    "    axs[ix].set_xticks(ticks=range(len(merged_renamed.mt_system)),\n",
    "                       labels=merged_renamed.mt_system,\n",
    "                       rotation=30, fontsize=8,\n",
    "                       fontdict={'horizontalalignment': 'right'})\n",
    "    axs[ix].get_legend().set_visible(False)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../outputs/wmt24/plots/BLASER2-vs-hum-by-language.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(5, 2, figsize=(10, 20))\n",
    "axs = axs.flat\n",
    "\n",
    "for ix, lp in enumerate(lang_pairs):\n",
    "    lp_tuple = lp.split('-')\n",
    "\n",
    "    blaser_res = results[ix]\n",
    "\n",
    "    g_txt = sns.histplot(blaser_res.text_source,\n",
    "                        ax=axs[ix],\n",
    "                        label='Text source',\n",
    "                        bins=100)\n",
    "    g_au = sns.histplot(blaser_res.audio_source,\n",
    "                        ax=axs[ix],\n",
    "                        label='Audio source',\n",
    "                        bins=100)\n",
    "    axs[ix].set_title(lp)\n",
    "    axs[ix].set_xlabel('BLASER-2 score')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../outputs/wmt24/plots/BLASER2-audio-vs-text-by-lang.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots()\n",
    "plt.scatter(range(len(lang_pairs)), tau_txt, label=\"Text source\")\n",
    "plt.scatter(range(len(lang_pairs)), tau_audio, label=\"Audio source\")\n",
    "plt.xticks(ticks=range(len(lang_pairs)), labels=lang_pairs)\n",
    "plt.xlabel(\"Language pair\")\n",
    "plt.ylabel(\"Tau (human rank vs. BLASER rank)\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_res = pd.concat(results)\n",
    "grouped_mean_lang = all_res[['audio_source', 'text_source', 'lang_pair']].groupby(\n",
    "        'lang_pair').mean().reset_index()\n",
    "fig, axs = plt.subplots()\n",
    "grouped_mean_lang.plot(kind='bar', ax=axs)\n",
    "axs.set_xticks(ticks=range(10), labels=grouped_mean_lang.lang_pair, rotation=0)\n",
    "axs.set_xlabel(\"Language pair\")\n",
    "axs.set_ylabel(\"Mean BLASER-2 score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots()\n",
    "g = sns.histplot(all_res.audio_source, ax=axs, label='Audio source')\n",
    "g = sns.histplot(all_res.text_source, ax=axs, label=\"Text source\")\n",
    "g.set_xlabel(\"BLASER-2 score\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_blaser_results = pd.concat(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_es_only = all_blaser_results[all_blaser_results.lang_pair == 'en-es']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_es_only[(en_es_only.audio_source > 4) & (en_es_only.text_source > 4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".mt-metrics-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
