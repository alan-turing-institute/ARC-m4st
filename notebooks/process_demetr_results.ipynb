{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import yaml\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categories as specified in the dataset are different to the paper\n",
    "# This gives the mapping between them\n",
    "with open(\"../configs/demetr/cat_correction.yaml\") as stream:\n",
    "    try:\n",
    "        cat_correction = yaml.safe_load(stream)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map categories to error severity\n",
    "# Severity is as specified in the paper\n",
    "with open(\"../configs/demetr/cat_severity.yaml\") as stream:\n",
    "    try:\n",
    "        cat_severity = yaml.safe_load(stream)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load M4ST results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the root directory holding the output JSON files from running\n",
    "# scripts/demetr/process_demetr.py\n",
    "# They are also available in the project Sharepoint\n",
    "m4st_res_dir = \"../outputs/demetr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_files = os.listdir(m4st_res_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all files into a single dataframe\n",
    "results_dataframes = []\n",
    "\n",
    "for i in range(len(res_files)):\n",
    "    try:\n",
    "        res_file = res_files[i]\n",
    "        res_df = pd.read_json(os.path.join(m4st_res_dir, res_file))\n",
    "\n",
    "        # Get category\n",
    "        cat_search = re.search(\"_id.(.)?_\", res_file)\n",
    "        cat_span = cat_search.span()\n",
    "        cat = res_file[cat_span[0] : cat_span[1]].strip(\"_id\")\n",
    "\n",
    "        # Get metric name\n",
    "        name_search = re.search(\"_(base|critical|major|minor)\", res_file)\n",
    "        name_span = name_search.span()\n",
    "        metric = res_file[: name_span[0]]\n",
    "\n",
    "        res_df = res_df.T\n",
    "\n",
    "        # MetricX produces MQM-style scores, meaning that a lower score indicates a\n",
    "        # better translation (scores are out of 25)\n",
    "        # Reverse scores so that they match the other metrics (lower is worse)\n",
    "        if \"metricx\" in metric:\n",
    "            res_df[\"mt_score\"] = 25 - res_df.mt_score\n",
    "            res_df[\"disfluent_score\"] = 25 - res_df.disfluent_score\n",
    "\n",
    "        res_df[\"metric\"] = metric\n",
    "        res_df[\"sentence_id\"] = res_df.index\n",
    "        res_df[\"category\"] = int(cat)\n",
    "        results_dataframes.append(res_df)\n",
    "    except IsADirectoryError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_res = pd.concat(results_dataframes)\n",
    "all_res.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct categories to align with the paper\n",
    "all_res[\"category\"] = all_res[\"category\"].replace(cat_correction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column indicating DEMETR accuracy\n",
    "all_res[\"correct\"] = all_res[\"mt_score\"] > all_res[\"disfluent_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy is reversed for category 35 (reference as translation) so need to adjust that\n",
    "cat_to_rev = all_res.loc[all_res[\"category\"] == 35]\n",
    "cat_to_rev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_to_rev[\"correct\"] = cat_to_rev[\"mt_score\"] < cat_to_rev[\"disfluent_score\"]\n",
    "cat_to_rev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reassign values to original dataframe\n",
    "all_res.loc[all_res[\"category\"] == 35, \"correct\"] = cat_to_rev.correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check result\n",
    "all_res.loc[all_res[\"category\"] == 35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column for severity\n",
    "all_res[\"severity\"] = all_res[\"category\"].map(cat_severity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dataframe\n",
    "all_res.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save out to file so we have a corrected set of results\n",
    "all_res.to_csv(\"../outputs/demetr/all/all.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tidy up naming for plotting\n",
    "all_res[\"metric\"] = all_res.metric.replace(\n",
    "    {\n",
    "        \"wmt22-comet-da\": \"COMET-22-Ref\",\n",
    "        \"COMET_Ref\": \"COMET-21-Ref\",\n",
    "        \"COMET-QE\": \"COMET-21-QE\",\n",
    "        \"wmt22-cometkiwi-da\": \"COMETKiwi-22\",\n",
    "        \"Bleu\": \"BLEU\",\n",
    "        \"BLASER_QE\": \"BLASER-2_QE\",\n",
    "        \"BLASER_Ref\": \"BLASER-2_Ref\",\n",
    "        \"google_metricx-24-hybrid-large-v2p6-bfloat16_qe\": \"MetricX-24L-16-QE\",\n",
    "        \"google_metricx-24-hybrid-large-v2p6_qe\": \"MetricX-24L-QE\",\n",
    "        \"google_metricx-24-hybrid-xl-v2p6-bfloat16_qe\": \"MetricX-24XL-16-QE\",\n",
    "        \"google_metricx-24-hybrid-xl-v2p6_qe\": \"MetricX-24XL-QE\",\n",
    "        \"google_metricx-24-hybrid-xxl-v2p6_qe\": \"MetricX-24XXL-QE\",\n",
    "        \"google_metricx-24-hybrid-xxl-v2p6-bfloat16_qe\": \"MetricX-24XXL-16-QE\",\n",
    "        \"google_metricx-24-hybrid-xl-v2p6_ref\": \"MetricX-24XL-Ref\",\n",
    "        \"google_metricx-24-hybrid-xl-v2p6-bfloat16_ref\": \"MetricX-24XL-16-Ref\",\n",
    "        \"google_metricx-24-hybrid-xxl-v2p6-bfloat16_ref\": \"MetricX-24XXL-16-Ref\",\n",
    "        \"google_metricx-24-hybrid-xxl-v2p6_ref\": \"MetricX-24XXL-Ref\",\n",
    "        \"google_metricx-24-hybrid-large-v2p6-bfloat16_ref\": \"MetricX-24L-16-Ref\",\n",
    "        \"google_metricx-24-hybrid-large-v2p6_ref\": \"MetricX-24L-Ref\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall mean accuracy by metric\n",
    "all_res.groupby(\"metric\").correct.mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots()\n",
    "by_language = all_res.groupby(\"source_language\")[\"correct\"].mean()\n",
    "axs.plot(by_language, \"x\")\n",
    "plt.xticks(np.arange(10), by_language.index, rotation=45)\n",
    "plt.ylabel(\"DEMETR accuracy (%)\")\n",
    "plt.xlabel(\"Source language\")\n",
    "plt.title(\"Mean performance across all 35 categories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots()\n",
    "by_severity = all_res.groupby(\"severity\")[\"correct\"].mean()\n",
    "by_severity.plot(kind=\"bar\")\n",
    "plt.xticks(np.arange(4), by_severity.index, rotation=0)\n",
    "plt.ylabel(\"DEMETR accuracy\")\n",
    "plt.xlabel(\"Severity\")\n",
    "plt.title(\"Mean performance for each error type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots()\n",
    "sev_by_lang = all_res.groupby([\"source_language\", \"severity\"])[\"correct\"].mean()\n",
    "sev_by_lang.unstack().plot(kind=\"bar\", ax=axs)\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel(\"DEMETR accuracy\")\n",
    "plt.xlabel(\"Source language\")\n",
    "plt.title(\"Mean performance for each severity level, by language\")\n",
    "plt.legend(loc=\"right\", bbox_to_anchor=(1.25, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots()\n",
    "sev_by_lang = all_res.groupby([\"source_language\", \"metric\"])[\"correct\"].mean()\n",
    "sev_by_lang.unstack().plot(kind=\"bar\", ax=axs)\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel(\"DEMETR accuracy\")\n",
    "plt.xlabel(\"Source language\")\n",
    "plt.title(\"Mean performance for each metric, by language\")\n",
    "plt.legend(loc=\"right\", bbox_to_anchor=(1.4, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots()\n",
    "to_table = sev_by_lang.reset_index()\n",
    "sev_by_lang = all_res.groupby([\"source_language\", \"metric\"])[\"correct\"].mean()\n",
    "sev_by_lang.unstack().plot(kind=\"bar\", ax=axs)\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel(\"DEMETR accuracy\")\n",
    "plt.xlabel(\"Source language\")\n",
    "plt.title(\"Mean performance for COMET metrics, by language\")\n",
    "plt.legend(loc=\"right\", bbox_to_anchor=(1.4, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots()\n",
    "sorted_overall_mean = (\n",
    "    all_res.groupby([\"metric\"])[\"correct\"].mean().sort_values(ascending=False)\n",
    ")\n",
    "axs.plot(sorted_overall_mean, \"x\")\n",
    "plt.xticks(rotation=30)\n",
    "plt.xlabel(\"Metric\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "# plt.title(\"Mean performance across all languages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_by_category = (\n",
    "    all_res.groupby([\"metric\", \"category\"])[\"correct\"].mean().reset_index()\n",
    ")\n",
    "corr_by_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_to_plot = [\n",
    "    \"BLEU\",\n",
    "    \"COMET-22-Ref\",\n",
    "    \"MetricX-24L-Ref\",\n",
    "    \"XCOMET-XL\",\n",
    "    \"BLASER-2_Ref\",\n",
    "    \"ChrF2\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_by_category = corr_by_category[corr_by_category.metric.isin(metrics_to_plot)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = corr_by_category.groupby(\"metric\").median().sort_values(by=\"correct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots()\n",
    "g = sns.boxplot(\n",
    "    corr_by_category,\n",
    "    x=\"metric\",\n",
    "    y=\"correct\",\n",
    "    fill=False,\n",
    "    ax=axs,\n",
    "    width=0.5,\n",
    "    order=grouped.index,\n",
    ")\n",
    "axs.set_xticklabels(rotation=20, labels=axs.get_xticklabels())\n",
    "axs.set_xlabel(\"Metric\")\n",
    "axs.set_ylabel(\"Accuracy\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../outputs/demetr/plots/metrics-boxplot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots()\n",
    "res_subset = all_res[all_res.metric.isin(metrics_to_plot)]\n",
    "sev_by_lang = res_subset.groupby([\"metric\", \"severity\"])[\"correct\"].mean()\n",
    "sev_by_lang = sev_by_lang.unstack()\n",
    "sev_by_lang.plot(kind=\"barh\", ax=axs)\n",
    "plt.xticks(rotation=0)\n",
    "plt.xlabel(\"DEMETR accuracy\")\n",
    "plt.ylabel(\"Metric\")\n",
    "# plt.title(\"Mean performance for each severity level by metric\")\n",
    "plt.legend(bbox_to_anchor=(1, 1))\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../outputs/demetr/plots/demetr-by-severity.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots()\n",
    "sev_by_lang = all_res.groupby([\"metric\", \"severity\"])[\"correct\"].mean()\n",
    "sev_by_lang.unstack().plot(kind=\"bar\", ax=axs)\n",
    "plt.xticks(rotation=30)\n",
    "plt.ylabel(\"DEMETR accuracy\")\n",
    "plt.xlabel(\"Metric\")\n",
    "# plt.title(\"Mean performance by severity for COMET metrics\")\n",
    "plt.legend(loc=\"right\", bbox_to_anchor=(1.23, 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLASER only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at BLASER performance for three different perturbation types, for different language pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m4st_res_dir = \"../outputs/demetr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blaser_new_15 = pd.read_json(\n",
    "    os.path.join(m4st_res_dir, \"BLASER_REF_minor_id15_case.json\")\n",
    ")\n",
    "blaser_new_8 = pd.read_json(\n",
    "    os.path.join(m4st_res_dir, \"BLASER_Ref_critical_id8_negation.json\")\n",
    ")\n",
    "blaser_new_6 = pd.read_json(\n",
    "    os.path.join(m4st_res_dir, \"BLASER_Ref_critical_id6_addition.json\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blaser_new_15 = blaser_new_15.T\n",
    "blaser_new_8 = blaser_new_8.T\n",
    "blaser_new_6 = blaser_new_6.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blaser_new_15[\"diff\"] = blaser_new_15.mt_score - blaser_new_15.disfluent_score\n",
    "blaser_new_8[\"diff\"] = blaser_new_8.mt_score - blaser_new_8.disfluent_score\n",
    "blaser_new_6[\"diff\"] = blaser_new_6.mt_score - blaser_new_6.disfluent_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots()\n",
    "blaser_new_15.groupby(\"source_language\").mean()[\"diff\"].plot(ax=axs)\n",
    "blaser_new_8.groupby(\"source_language\").mean()[\"diff\"].plot(ax=axs)\n",
    "blaser_new_6.groupby(\"source_language\").mean()[\"diff\"].plot(ax=axs)\n",
    "\n",
    "fig.legend(\n",
    "    labels=[\"Pronoun case\", \"Negation\", \"Addition\"],\n",
    "    loc=\"right\",\n",
    "    bbox_to_anchor=(1.15, 0.5),\n",
    ")\n",
    "axs.set_ylabel(\"Score difference\")\n",
    "plt.xticks(np.arange(10), np.unique(blaser_new_15.source_language), rotation=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
